# The Multimodal Live API Documentation

## Overview

The Multimodal Live API enables low-latency bidirectional voice and video interactions with Gemini. With this API, you can provide end users with natural, human-like voice conversations, including the ability to interrupt the model’s responses using voice commands. The model can process text, audio, and video input, and it can provide both text and audio output.

## Capabilities

- **Multimodality:** The model can see, hear, and speak.
- **Low-Latency Real-Time Interaction:** Provides fast responses.
- **Session Memory:** Retains all interactions within a session.
- **Function Calling, Code Execution, and Search Integration:** Enables external service and data source integration.
- **Automated Voice Activity Detection (VAD):** Recognizes when the user starts and stops speaking, allowing natural, conversational interactions.

> You can try the Multimodal Live API in [Google AI Studio](https://aistudio.google.com).

## Get Started

### API Overview

The Multimodal Live API is a stateful API that uses WebSockets.

### Installation and Setup

#### Install the Gemini API Library

To install the `google-genai` package, use the following command:

```bash
pip install google-genai
````

#### Import Dependencies

```python
from google import genai
```

### Example: Send and Receive a Text Message

```python
import asyncio
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY", http_options={'api_version': 'v1alpha'})
model_id = "gemini-2.0-flash-exp"
config = {"response_modalities": ["TEXT"]}

async def main():
    async with client.aio.live.connect(model=model_id, config=config) as session:
        while True:
            message = input("User> ")
            if message.lower() == "exit":
                break
            await session.send(input=message, end_of_turn=True)

            async for response in session.receive():
                if response.text is None:
                    continue
                print(response.text, end="")

if __name__ == "__main__":
    asyncio.run(main())
```

## Integration Guide

### Sessions

A WebSocket connection establishes a session between the client and the Gemini server. Once connected, you can:

- **Send:** Text, audio, or video to the Gemini server.
- **Receive:** Audio, text, or function call requests from the Gemini server.

The session configuration is sent in the first message after connection and includes the model, generation parameters, system instructions, and tools.

#### Example Configuration

```json
{
  "model": "string",
  "generationConfig": {
    "candidateCount": "integer",
    "maxOutputTokens": "integer",
    "temperature": "number",
    "topP": "number",
    "topK": "integer",
    "presencePenalty": "number",
    "frequencyPenalty": "number",
    "responseModalities": ["string"],
    "speechConfig": "object"
  },
  "systemInstruction": "string",
  "tools": ["object"]
}
```

See the reference for `BidiGenerateContentSetup` for more details.

### Sending Messages

Messages are JSON-formatted objects exchanged over the WebSocket. The client must send a JSON object with exactly one of the following fields:

```json
{
  "setup": "BidiGenerateContentSetup",
  "clientContent": "BidiGenerateContentClientContent",
  "realtimeInput": "BidiGenerateContentRealtimeInput",
  "toolResponse": "BidiGenerateContentToolResponse"
}
```

#### Supported Client Messages

|**Message**|**Description**|
|---|---|
|`BidiGenerateContentSetup`|Session configuration to be sent in the first message|
|`BidiGenerateContentClientContent`|Incremental content update of the current conversation from the client|
|`BidiGenerateContentRealtimeInput`|Real-time audio or video input|
|`BidiGenerateContentToolResponse`|Response to a ToolCallMessage received from the server|

### Receiving Messages

To receive messages, listen for the WebSocket “message” event and parse the result. For example:

```javascript
ws.addEventListener("message", async (evt) => {
  if (evt.data instanceof Blob) {
    // Process the received data (audio, video, etc.)
  } else {
    // Process JSON response
  }
});
```

Server messages will include one of the following fields:

```json
{
  "setupComplete": "BidiGenerateContentSetupComplete",
  "serverContent": "BidiGenerateContentServerContent",
  "toolCall": "BidiGenerateContentToolCall",
  "toolCallCancellation": "BidiGenerateContentToolCallCancellation"
}
```

#### Supported Server Messages

|**Message**|**Description**|
|---|---|
|`BidiGenerateContentSetupComplete`|Acknowledges that the session setup is complete|
|`BidiGenerateContentServerContent`|Content generated by the model in response to a client message|
|`BidiGenerateContentToolCall`|Request for the client to execute function calls and return responses|
|`BidiGenerateContentToolCallCancellation`|Notification to cancel a function call due to a user interruption|

### Incremental Content Updates

Use incremental updates to send text input, establish, or restore session context. For short contexts, send turn-by-turn interactions; for longer contexts, provide a single summary message.

#### Example

```json
{
  "clientContent": {
    "turns": [
      {
        "parts": [
          {
            "text": ""
          }
        ],
        "role": "user"
      },
      {
        "parts": [
          {
            "text": ""
          }
        ],
        "role": "model"
      }
    ],
    "turnComplete": true
  }
}
```

_Note:_ Use `BidiGenerateContentToolResponse` for function call responses. `BidiGenerateContentClientContent`should only be used to establish previous context or provide text input to the conversation.

### Streaming Audio and Video

For a streaming audio and video example, run the “Multimodal Live API - Quickstart” notebook in one of the following environments:

- [Open in Colab](https://colab.research.google.com/)
- [View on GitHub](https://github.com/)

### Function Calling

- **Declaration:** All functions must be declared at the start of the session via tool definitions in the `BidiGenerateContentSetup` message.
- **Multiple Calls:** The model can generate multiple function calls and the code to chain outputs.
- **Sequential Processing:** Execution pauses until each function call’s result is available.
- **Response:** The client should respond with a `BidiGenerateContentToolResponse`.

_Note:_ Audio inputs and outputs may negatively impact the model’s ability to use function calling.

### Audio Formats

- **Input Audio Format:** Raw 16-bit PCM audio at 16kHz (little-endian)
- **Output Audio Format:** Raw 16-bit PCM audio at 24kHz (little-endian)

### System Instructions

System instructions are provided at the start of the session and remain in effect throughout. They control the model’s tone, sentiment, and output. Subsequent inputs should use incremental updates.

### Interruptions

- Users can interrupt the model’s output at any time.
- When voice activity detection (VAD) detects an interruption, the ongoing generation is canceled.
- The server sends a `BidiGenerateContentServerContent` message to report the interruption.
- Any pending function calls are canceled, and the server sends a cancellation message with the corresponding IDs.

### Voices

The API supports the following voices: **Aoede, Charon, Fenrir, Kore,** and **Puck**.

To specify a voice, set the `voiceName` in the `speechConfig` object of your session configuration:

```json
{
  "voiceConfig": {
    "prebuiltVoiceConfig": {
      "voiceName": "VOICE_NAME"
    }
  }
}
```

### Limitations

- **Client Authentication:** Only server-to-server authentication is provided. Use an intermediate server for secure client integration.
- **Conversation History:** Session context is erased after the session ends. Maintain your own log to restore history.
- **Session Duration:** Limited to 15 minutes for audio or 2 minutes for audio and video. Exceeding this terminates the connection.
- **Token Count:** Not supported.
- **Rate Limits:**
    - 3 concurrent sessions per API key
    - 4M tokens per minute

## Messages and Events

### BidiGenerateContentClientContent

**Incremental update of the current conversation delivered from the client.** All content here is unconditionally appended to the conversation history and used as part of the prompt to the model to generate content.

A message here will interrupt any current model generation.

**Fields:**

- `turns[]`  
    Content appended to the current conversation with the model. For single-turn queries, this is a single instance. For multi-turn queries, this is a repeated field containing conversation history and the latest request.
- `turn_complete` (bool)  
    If true, indicates that the server content generation should start with the currently accumulated prompt. Otherwise, the server awaits additional messages before starting generation.

### BidiGenerateContentRealtimeInput

**User input that is sent in real time.**

This differs from `BidiGenerateContentClientContent` in a few ways:

- Can be sent continuously without interruption to model generation.
- End of turn is derived from user activity (for example, end of speech).
- Data is processed incrementally as it arrives, minimizing latency.

**Fields:**

- `media_chunks[]`  
    Inlined bytes data for media input.

### BidiGenerateContentServerContent

**Incremental server update generated by the model in response to client messages.**

**Fields:**

- `turn_complete` (bool)  
    Indicates that the model is done generating. Generation will only start in response to additional client messages.
- `interrupted` (bool)  
    Indicates that a client message interrupted current model generation.
- `grounding_metadata` (`GroundingMetadata`)  
    Grounding metadata for the generated content.
- `model_turn` (`Content`)  
    The content that the model has generated as part of the current conversation.

### BidiGenerateContentSetup

**Message to be sent in the first (and only the first) client message.** Contains configuration that applies for the duration of the streaming session.

**Fields:**

- `model` (string)  
    **Required.** The model’s resource name (format: `models/{model}`).
- `generation_config` (`GenerationConfig`)  
    Optional generation parameters. The following fields are not supported:  
    `responseLogprobs, responseMimeType, logprobs, responseSchema, stopSequence, routingConfig, audioTimestamp`
- `system_instruction` (`Content`)  
    Optional system instructions for the model.
- `tools[]` (`Tool`)  
    Optional list of Tools the model may use to generate the next response.

### BidiGenerateContentSetupComplete

**No fields.**  
Sent in response to a `BidiGenerateContentSetup` message from the client.

### BidiGenerateContentToolCall

**Request for the client to execute the function calls and return the responses.**

**Fields:**

- `function_calls[]` (`FunctionCall`)  
    The function calls to be executed.

### BidiGenerateContentToolCallCancellation

**Notification that a previously issued ToolCallMessage should be canceled.**  
If side effects occurred, clients may attempt to undo them. This occurs only if clients interrupt the server’s turn.

**Fields:**

- `ids[]` (string)  
    The IDs of the tool calls to be canceled.

### BidiGenerateContentToolResponse

**Client-generated response to a ToolCall received from the server.**  
Individual `FunctionResponse` objects are matched to the respective `FunctionCall` objects by the `id` field.

**Fields:**

- `function_responses[]` (`FunctionResponse`)  
    The response to the function calls.